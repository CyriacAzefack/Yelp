{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-7053b71d88f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# remove spark heavy logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlog4j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog4j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlog4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetRootLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# HDFS Base path for Yelp Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "# remove spark heavy logging\n",
    "log4j = sc._jvm.org.apache.log4j\n",
    "log4j.LogManager.getRootLogger().setLevel(log4j.Level.ERROR)\n",
    "\n",
    "# HDFS Base path for Yelp Data\n",
    "base_path = '/shared/yelp/json'\n",
    "\n",
    "# Yelp file types list\n",
    "file_type_list = ['businesses', 'checkins', 'reviews', 'tips', 'users']\n",
    "\n",
    "# Dataframe dictionnary for each file type\n",
    "dataframe_map = {t: sqlContext.read.json(base_path + '/%s' % t)\n",
    "                 for t in file_type_list}\n",
    "\n",
    "# Printing dataframes' schema\n",
    "for t in file_type_list:\n",
    "    print('Schema for %s:' % t)\n",
    "    dataframe_map[t].printSchema()\n",
    "    print('*' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DateType\n",
    "import datetime\n",
    "import pandas as pd\n",
    "format_date = udf(lambda date: datetime.datetime.strptime(date, '%Y-%m-%d'), DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_reviews = dataframe_map['reviews']\n",
    "df_users = dataframe_map['users']\n",
    "df_tips = dataframe_map['tips']\n",
    "df_reviews = df_reviews.withColumn('date', format_date(df_reviews.date))\n",
    "df_tips = df_tips.withColumn('date', format_date(df_tips.date))\n",
    "db = dataframe_map['businesses']\n",
    "df_businesses = db.where(db.city == 'Las Vegas').sample(False,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import collections as c\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "apply_len = udf(lambda s: len(s), IntegerType())\n",
    "df_reviews = df_reviews.withColumnRenamed('user_id', 'user_id_r')\n",
    "alpha = df_users.join(df_reviews, df_users.user_id == df_reviews.user_id_r, 'inner')\n",
    "alpha = alpha.withColumnRenamed('review_count', 'review_count_alpha');\n",
    "beta = alpha.join(df_businesses, alpha.business_id == df_businesses.business_id, 'inner')\n",
    "temp = beta['average_stars','elite', 'fans', 'friends', 'review_count', 'yelping_since', 'user_id']\n",
    "temp = temp.withColumn('elite_len', apply_len(temp.elite).alias('elite_len'))\n",
    "temp = temp.withColumn('friends_len', apply_len(temp.friends).alias('friends_len'))\n",
    "users = temp['average_stars','fans', 'review_count','elite_len', 'friends_len']\n",
    "users = users.toPandas()\n",
    "temp = temp['average_stars','fans', 'review_count','elite_len', 'friends_len', 'user_id']\n",
    "temp = temp.toPandas()\n",
    "users_norm = (users - users.mean())/(users.max() - users.min())\n",
    "users_norm = users_norm.as_matrix()\n",
    "kmeans = KMeans(n_clusters=3, random_state=None).fit(users_norm)\n",
    "#dummies = pd.get_dummies(users)\n",
    "#del dummies['automotive']\n",
    "#print dummies.columns\n",
    "kmeans.labels_[0:20]\n",
    "c.Counter(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Choix du nombre de clusters => calcul de silhouette moyenne\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "range_n_clusters = [2, 3, 4, 5, 6]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=10).fit(users_norm)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    silhouette_avg = silhouette_score(users_norm, cluster_labels, sample_size = 5000)\n",
    "    print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_users.collect()[2][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On récupère le nombre de reviews faite par user sur la ville de Las Vegas\n",
    "reviews_by_user = df_reviews.join(df_businesses,df_reviews.business_id == df_businesses.business_id, 'inner').groupby(['user_id']).count()\n",
    "tips_by_user = df_tips.join(df_businesses,df_tips.business_id == df_businesses.business_id, 'inner').groupby(['user_id']).count()\n",
    "reviews_by_user = reviews_by_user.withColumnRenamed('count', 'count_reviews')\n",
    "tips_by_user = tips_by_user.withColumnRenamed('count', 'count_tips')\n",
    "tips_by_user = tips_by_user.withColumnRenamed('user_id', 'user_id_t')\n",
    "count_tips_reviews = reviews_by_user.join(tips_by_user, reviews_by_user.user_id == tips_by_user.user_id_t, 'inner')\n",
    "count_tips_reviews = count_tips_reviews['user_id', 'count_reviews', 'count_tips']\n",
    "count_tips_reviews = count_tips_reviews.withColumn('count_total', count_tips_reviews.count_tips+count_tips_reviews.count_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_reviews = [];\n",
    "nb_tips = [];\n",
    "nb_manif = [];\n",
    "s1 = count_tips_reviews.collect()[8]\n",
    "s2 = count_tips_reviews.collect()[43]\n",
    "s3 = count_tips_reviews.collect()[73]\n",
    "x = sqlContext.createDataFrame([(s1[0], s1[1], s1[2], s1[3]),(s2[0], s2[1], s2[2], s2[3]), (s3[0], s3[1], s3[2], s3[3])])\n",
    "x = x.withColumnRenamed('_1', 'user_id')\n",
    "x = x.withColumnRenamed('_2', 'count_reviews')\n",
    "x = x.withColumnRenamed('_3', 'count_tips')\n",
    "x = x.withColumnRenamed('_4', 'count_total')\n",
    "x = x.orderBy(x.count_total, ascending=False)\n",
    "# x = count_tips_reviews.filter(count_tips_reviews.count_total > 100).orderBy(count_tips_reviews.count_total, ascending = False)\n",
    "v = x.count();\n",
    "for k in xrange(v):\n",
    "    nb_reviews.append(x.collect()[k][1]);\n",
    "    nb_tips.append(x.collect()[k][2]);\n",
    "    nb_manif.append(x.collect()[k][3]);\n",
    "    \n",
    "x = x.withColumnRenamed('user_id', 'user_id_ys')\n",
    "df_reviews = df_reviews.withColumnRenamed('business_id', 'business_id_r')\n",
    "df_tips = df_tips.withColumnRenamed('business_id', 'business_id_t')\n",
    "df = x.join(df_reviews, df_reviews.user_id_r ==  x.user_id_ys, 'inner')\n",
    "df2 = df.join(df_businesses, df_businesses.business_id == df.business_id_r, 'inner').orderBy(df.count_total, ascending=False)\n",
    "df2 = df2['user_id_ys','date', 'business_id', 'count_total']\n",
    "dfbis = x.join(df_tips, df_tips.user_id ==  x.user_id_ys, 'inner')\n",
    "df2bis = dfbis.join(df_businesses, df_businesses.business_id == dfbis.business_id_t, 'inner').orderBy(dfbis.count_total, ascending=False)\n",
    "df2bis = df2bis['user_id_ys','date', 'business_id', 'count_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Liste pour stocker , pour chaque yelper star, le nombre de fois qu'il a influencé chacun de ses amis\n",
    "friends_by_user = [];\n",
    "for i in xrange(len(nb_manif)):\n",
    "    user_id_yelperstar = x.collect()[i][0];\n",
    "    reviews_made_by_ys = df2.where(df2.user_id_ys == user_id_yelperstar);\n",
    "    tips_made_by_ys = df2bis.where(df2bis.user_id_ys == user_id_yelperstar);\n",
    "    manif_made_by_ys = reviews_made_by_ys.unionAll(tips_made_by_ys);\n",
    "    # Liste des amis du ième yelper star\n",
    "    list_friends_user = df_users.where(df_users.user_id == user_id_yelperstar).collect()[0][4];\n",
    "    specific_friend = [0]*len(list_friends_user);\n",
    "\tfor j in xrange(nb_manif[i]):     \n",
    "        date_manif = manif_made_by_ys.collect()[j][1];\n",
    "        date_manif_converted = pd.to_datetime(date_manif);\n",
    "        delta_month = datetime.timedelta(7);\n",
    "        date_business_manif = date_manif_converted + delta_month;\n",
    "        x_reviews = df_reviews.where((df_reviews.business_id_r == manif_made_by_ys.collect()[j][2]) & (date_manif <= df_reviews.date) & (df_reviews.date < date_business_manif.to_datetime()));\n",
    "        x_tips = df_tips.where((df_tips.business_id_t == manif_made_by_ys.collect()[j][2]) & (date_manif < df_tips.date) & (df_tips.date < date_business_manif.to_datetime()));\n",
    "        x_reviews = x_reviews['business_id_r', 'date', 'user_id_r'];\n",
    "        x_tips = x_tips['business_id_t', 'date', 'user_id'];\n",
    "        x_manif = x_reviews.unionAll(x_tips);\n",
    "        nombre_manif = x_manif.count();\n",
    "        for k in xrange(nombre_manif):\n",
    "            if(x_manif.collect()[k][2] in list_friends_user):\n",
    "                m = list_friends_user.index(x_manif.collect()[k][2]);\n",
    "                specific_friend[m] = specific_friend[m] + 1;\n",
    "                print 'Youpi, une influence !'\n",
    "    \n",
    "    friends_by_user.append(specific_friend);\n",
    "    print 'Le user '+x.collect()[i][0]+' a influence '+str(sum(friends_by_user[i]))+' fois ses amis';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# le seuil de validation correspond au nombre moyen minimal de yelper influencé par une review/tip que l'on accepte \n",
    "# pour pouvoir considérer l'individu comme étant effectivement un yelper star\n",
    "seuil_validation = 1\n",
    "for i in xrange(len(friends_by_user)):\n",
    "    if(sum(friends_by_user[i])/nb_manif[i] < seuil_validation):\n",
    "        print 'FAILURE : Yelper Stars REJECTED...'\n",
    "        break;\n",
    "    elif(i == len(friends_by_user) - 1):\n",
    "        print 'SUCCESS : Yelper Stars VALIDATED'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "pySpark (Spark 1.6.2)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
